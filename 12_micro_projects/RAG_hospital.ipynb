{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YeOn0WiwZ1G"
      },
      "outputs": [],
      "source": [
        "!pip install langchain --quiet\n",
        "!pip install google-ai-generativelanguage --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgJ_9ZsaxscZ"
      },
      "outputs": [],
      "source": [
        "!pip install google-ai-generativelanguage --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WZlVTDJYx0WU"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_google_genai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D6xHI421y2yP"
      },
      "outputs": [],
      "source": [
        "! pip install langchain-community --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YCXBCXNbwf9G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "#google API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3y7-DPU9whZ7"
      },
      "outputs": [],
      "source": [
        "#from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9NIITe0awjMS"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "gemini_flash = ChatGoogleGenerativeAI(\n",
        "    model=\"models/gemini-1.5-flash\",\n",
        "    temperature=0.2,\n",
        "    top_p=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QOPUIy9JwmwA",
        "outputId": "05e562b1-f0b8-4357-fb2f-aa3e87e6f8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of chunks: 139\n",
            "Sample chunk:\n",
            "1. General Hospital Information\n",
            "\n",
            "Department Details:\n",
            "\n",
            "Department: Neurology\n",
            "\n",
            "Head of Department: Dr. Eleanor Vance, MD, PhD\n",
            "\n",
            "Location: North Wing, 3rd Floor\n",
            "\n",
            "Contact Phone: (555) 123-4567\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "#loading synthetic text hospital data\n",
        "loader = TextLoader(\"/content/Synthetic-data-RAG.txt\")\n",
        "docs = loader.load()\n",
        "\n",
        "# Split into chunks\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=50)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "print(f\"Number of chunks: {len(chunks)}\")\n",
        "print(f\"Sample chunk:\\n{chunks[0].page_content}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vDayQekTyQiu"
      },
      "outputs": [],
      "source": [
        "! pip install faiss-cpu --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NELeOROe18Fn",
        "outputId": "9a00fc2d-2bf2-46bc-f075-b1ad9981d170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample chunk 1:\n",
            "1. General Hospital Information\n",
            "\n",
            "Department Details:\n",
            "\n",
            "Department: Neurology\n",
            "\n",
            "Head of Department: Dr. Eleanor Vance, MD, PhD\n",
            "\n",
            "Location: North Wing, 3rd Floor\n",
            "\n",
            "Contact Phone: (555) 123-4567\n",
            "---\n",
            "Sample chunk 2:\n",
            "Contact Phone: (555) 123-4567\n",
            "\n",
            "Services: Diagnosis and treatment of disorders of the nervous system, including brain, spinal cord, and peripheral nerves. Specializes in stroke, epilepsy, multiple sclerosis, Parkinson's disease, and neuro-oncology.\n",
            "\n",
            "Sub-specialties: Neuro-oncology Clinic, Stroke Unit, Epilepsy Monitoring Unit, Movement Disorders Clinic.\n",
            "\n",
            "Department: Oncology\n",
            "---\n",
            "Sample chunk 3:\n",
            "Department: Oncology\n",
            "\n",
            "Head of Department: Dr. Ben Carter, MD\n",
            "\n",
            "Location: East Wing, 2nd Floor\n",
            "\n",
            "Contact Phone: (555) 987-6543\n",
            "\n",
            "Services: Comprehensive cancer care including chemotherapy, immunotherapy, targeted therapy, and palliative care. Works in conjunction with Radiation Oncology and Surgical Oncology.\n",
            "---\n",
            "Sample chunk 4:\n",
            "Sub-specialties: Medical Oncology, Hematologic Malignancies, Solid Tumor Oncology (including Brain Tumor Program).\n",
            "\n",
            "Department: Radiology\n",
            "\n",
            "Head of Department: Dr. Anya Sharma, MD\n",
            "\n",
            "Location: Ground Floor, Central Wing\n",
            "\n",
            "Contact Phone: (555) 234-5678\n",
            "\n",
            "Services: Diagnostic imaging services including X-ray, CT scans, MRI scans, Ultrasound, PET scans, and interventional radiology procedures.\n",
            "---\n",
            "Sample chunk 5:\n",
            "Special Equipment: 3T MRI, PET-CT scanner, Bi-plane angiography suite.\n",
            "\n",
            "Department: Neurosurgery\n",
            "\n",
            "Head of Department: Dr. Marcus Chen, MD, FRCS\n",
            "\n",
            "Location: North Wing, 3rd Floor (shares reception with Neurology)\n",
            "\n",
            "Contact Phone: (555) 345-6789\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in range(min(5, len(chunks))):\n",
        "    print(f\"Sample chunk {i+1}:\\n{chunks[i].page_content}\\n---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VFGFM1LtyRBn"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "# embedding model (Gemini)\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "# vector store from the document chunks\n",
        "vectorstore = FAISS.from_documents(chunks, embedding_model)\n",
        "\n",
        "vectorstore.save_local(\"HospitalDB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-tANWauW2FhS",
        "outputId": "9de1a2c6-7eab-4f0e-d7ea-0cb7a3c9d3cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved documents based on a sample query:\n",
            "Content:\n",
            "Fatigue: This is very common. Rest when you need to, but try to incorporate gentle exercise like short walks. Prioritize tasks and ask for help.\n",
            "\n",
            "Hair Loss: If your chemo causes hair loss, it usually starts 2-3 weeks after treatment begins. Consider wigs, scarves, or hats. Hair usually regrows after treatment ends.\n",
            "Metadata: {'source': '/content/Synthetic-data-RAG.txt'}\n",
            "---\n",
            "Content:\n",
            "Common Symptoms: Symptoms depend on the tumor's location and size but can include headaches, seizures, weakness or numbness in limbs, speech difficulties, vision changes, and personality changes.\n",
            "\n",
            "Diagnosis: Diagnosis typically involves a neurological exam, MRI or CT scans, and a biopsy (surgical removal of a tissue sample for examination).\n",
            "Metadata: {'source': '/content/Synthetic-data-RAG.txt'}\n",
            "---\n",
            "Content:\n",
            "Q: Will I lose my hair?\n",
            "\n",
            "A: Hair loss (alopecia) is common but usually temporary and typically occurs only in the area being treated. Your radiation oncologist will discuss this with you.\n",
            "\n",
            "Q: What are common side effects?\n",
            "Metadata: {'source': '/content/Synthetic-data-RAG.txt'}\n",
            "---\n",
            "Content:\n",
            "Eat small, frequent meals instead of large ones.\n",
            "\n",
            "Try bland, easy-to-digest foods: toast, crackers, rice, bananas, applesauce, boiled chicken.\n",
            "\n",
            "Avoid greasy, spicy, or very sweet foods.\n",
            "\n",
            "Sip clear fluids (water, broth, ginger ale) throughout the day.\n",
            "\n",
            "Eat foods cold or at room temperature if smells bother you.\n",
            "\n",
            "Rinse your mouth before and after eating.\n",
            "Metadata: {'source': '/content/Synthetic-data-RAG.txt'}\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "retrieved_docs = vectorstore.similarity_search(\"What are the common symptoms of anxiety?\")\n",
        "\n",
        "print(\"Retrieved documents based on a sample query:\")\n",
        "for doc in retrieved_docs:\n",
        "    print(f\"Content:\\n{doc.page_content}\\nMetadata: {doc.metadata}\\n---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PGiJIxW8wqFD",
        "outputId": "81acfeec-1aa5-4668-ac6e-090d491a0d95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-124b8b5a61e1>:8: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(question)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dr. Eleanor Vance, MD, PhD\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Question\n",
        "question = \"who is Head of the department of Neurology?\"\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "\n",
        "docs = retriever.get_relevant_documents(question)\n",
        "context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Answer the question using ONLY the provided context.\\n\\nContext:\\n{context}\"),\n",
        "    (\"human\", \"{question}\")\n",
        "])\n",
        "\n",
        "chain = rag_prompt | gemini_flash\n",
        "\n",
        "response = chain.invoke({\"context\": context, \"question\": question})\n",
        "print(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eq98xOOI0jYk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}